#!/usr/bin/env python3
"""
Pipeline complÃ¨te FlashBack FA
Scraping des images + Extraction automatique des DataFrames par IA
"""

import os
import sys
import asyncio
import time
from pathlib import Path

def load_env_file():
    """Charge le fichier .env s'il existe"""
    env_file = Path('.env')
    if env_file.exists():
        try:
            with open(env_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#') and '=' in line:
                        key, value = line.split('=', 1)
                        os.environ[key] = value
        except Exception as e:
            print(f"âš ï¸ Erreur lors du chargement du fichier .env: {e}")

async def run_scraper():
    """Lance le scraper FlashBack FA"""
    print("ğŸ¯ Ã‰TAPE 1: SCRAPING DES IMAGES")
    print("=" * 50)
    
    try:
        # Importer et lancer le scraper
        from flashback_scraper import FlashBackScraper
        
        flashback_url = "https://sites.google.com/view/reglement-flashback-fa/accueil?authuser=0"
        
        print(f"ğŸŒ Site cible: {flashback_url}")
        print("ğŸ” Recherche d'images dans toutes les divs...")
        print("ğŸ“ Filtrage: > 100x100px, dÃ©tection de doublons")
        print()
        
        async with FlashBackScraper(
            base_url=flashback_url,
            output_dir="flashback_images",
            max_concurrent=6,  # Respectueux avec Google Sites
            delay_between_requests=0.8,  # Plus lent mais plus sÃ»r
            timeout=60
        ) as scraper:
            stats = await scraper.crawl_flashback_site()
            
            print("\nâœ… SCRAPING TERMINÃ‰!")
            print(f"ğŸ“Š RÃ©sultats:")
            print(f"   ğŸŒ Pages explorÃ©es: {stats['pages_crawled']}")
            print(f"   ğŸ–¼ï¸  Images dÃ©couvertes: {stats['images_found']}")
            print(f"   ğŸ’¾ Images tÃ©lÃ©chargÃ©es: {stats['images_downloaded']}")
            print(f"   ğŸ” Doublons supprimÃ©s: {scraper.stats['duplicates_removed']}")
            print(f"   ğŸ“ Images filtrÃ©es: {scraper.stats['size_filtered']}")
            
            if stats['images_found'] > 0:
                success_rate = (stats['images_downloaded'] / stats['images_found']) * 100
                print(f"   âœ… Taux de rÃ©ussite: {success_rate:.1f}%")
            
            return stats['images_downloaded'] > 0
            
    except ImportError as e:
        print(f"âŒ Erreur d'importation du scraper: {e}")
        print("   VÃ©rifiez que tous les modules sont installÃ©s")
        return False
    except Exception as e:
        print(f"âŒ Erreur lors du scraping: {e}")
        return False

def run_ai_extraction():
    """Lance l'extraction IA des DataFrames"""
    print("\nğŸ¯ Ã‰TAPE 2: EXTRACTION IA DES DATAFRAMES")
    print("=" * 50)
    
    try:
        # VÃ©rifier qu'on a des images
        images_dir = Path("flashback_images")
        if not images_dir.exists():
            print("âŒ Dossier 'flashback_images' non trouvÃ©!")
            return False
        
        # Compter les images
        image_count = sum(1 for ext in ['*.jpg', '*.jpeg', '*.png', '*.gif', '*.bmp', '*.webp'] 
                         for _ in images_dir.glob(ext))
        
        if image_count == 0:
            print(f"âŒ Aucune image trouvÃ©e dans {images_dir}")
            return False
        
        print(f"ğŸ“· {image_count} images trouvÃ©es pour analyse IA")
        print("ğŸ¤– GPT-4 Vision va analyser automatiquement tous les tableaux")
        print()
        
        # Importer et lancer l'extracteur IA
        from image_to_dataframe import UniversalTableExtractorAI
        
        ai_extractor = UniversalTableExtractorAI("flashback_images")
        dataframes_by_type = ai_extractor.process_all_images()
        
        if dataframes_by_type:
            total_elements = sum(len(df) for df in dataframes_by_type.values())
            print(f"\nğŸ“Š {total_elements} Ã©lÃ©ments dÃ©tectÃ©s dans {len(dataframes_by_type)} types de tableaux!")
            
            # Exporter les DataFrames
            ai_extractor.export_all_dataframes(dataframes_by_type)
            print("âœ… DataFrames exportÃ©s vers flashback_dataframes/")
            
            # Statistiques dÃ©taillÃ©es
            print(f"\nğŸ“ˆ Statistiques:")
            for table_type, df in dataframes_by_type.items():
                print(f"   ğŸ“‹ {table_type.capitalize()}: {len(df)} Ã©lÃ©ments")
                if table_type == 'armes' and 'Type' in df.columns:
                    type_counts = df['Type'].value_counts()
                    for weapon_type, count in type_counts.items():
                        print(f"      - {weapon_type}: {count} armes")
            
            print(f"\nğŸ¯ TOTAL: {total_elements} Ã©lÃ©ments extraits automatiquement!")
            return True
        else:
            print("âŒ Aucun tableau dÃ©tectÃ© par l'IA")
            return False
            
    except ImportError as e:
        print(f"âŒ Erreur d'importation de l'extracteur IA: {e}")
        print("   VÃ©rifiez que tous les modules sont installÃ©s")
        return False
    except Exception as e:
        print(f"âŒ Erreur lors de l'extraction IA: {e}")
        return False

def check_prerequisites():
    """VÃ©rifie que tous les prÃ©requis sont remplis"""
    print("ğŸ” VÃ‰RIFICATION DES PRÃ‰REQUIS")
    print("=" * 40)
    
    # VÃ©rifier la clÃ© API OpenAI
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        print("âŒ ClÃ© API OpenAI non configurÃ©e!")
        print()
        print("ğŸ”§ Solutions:")
        print("   1. Configurez automatiquement: python setup_openai.py")
        print("   2. Ou dÃ©finissez manuellement: export OPENAI_API_KEY=your_api_key")
        print("   3. Ou crÃ©ez un fichier .env avec: OPENAI_API_KEY=your_api_key")
        print()
        print("ğŸ’¡ Obtenez votre clÃ© API sur: https://platform.openai.com/api-keys")
        
        # Proposer de lancer la configuration
        choice = input("Voulez-vous configurer maintenant ? (O/n): ").lower()
        if choice not in ['n', 'non', 'no']:
            print()
            os.system("python setup_openai.py")
            # Recharger aprÃ¨s configuration
            load_env_file()
            api_key = os.getenv('OPENAI_API_KEY')
            if not api_key:
                print("âŒ Configuration Ã©chouÃ©e")
                return False
        else:
            return False
    
    print(f"âœ… ClÃ© API OpenAI configurÃ©e (***{api_key[-6:]})")
    
    # VÃ©rifier les modules requis
    missing_modules = []
    required_modules = [
        ('aiohttp', 'aiohttp'),
        ('aiofiles', 'aiofiles'),
        ('beautifulsoup4', 'bs4'),
        ('pandas', 'pandas'),
        ('openai', 'openai'),
        ('pillow', 'PIL'),
        ('tqdm', 'tqdm')
    ]
    
    for module_name, import_name in required_modules:
        try:
            __import__(import_name)
            print(f"âœ… {module_name}")
        except ImportError:
            missing_modules.append(module_name)
            print(f"âŒ {module_name}")
    
    if missing_modules:
        print(f"\nâŒ Modules manquants: {', '.join(missing_modules)}")
        print("   Installez avec: pip install -r requirements.txt")
        return False
    
    print("âœ… Tous les modules requis sont installÃ©s")
    return True

async def main():
    """Pipeline principale"""
    start_time = time.time()
    
    print("ğŸ® FLASHBACK FA - PIPELINE COMPLÃˆTE")
    print("ğŸ¤– SCRAPING + EXTRACTION IA AUTOMATIQUE")
    print("=" * 60)
    print()
    
    # Charger les variables d'environnement
    load_env_file()
    
    # VÃ©rifier les prÃ©requis
    if not check_prerequisites():
        print("\nâŒ PrÃ©requis non remplis. Veuillez corriger avant de continuer.")
        return
    
    print("\nğŸš€ Tous les prÃ©requis sont OK, dÃ©marrage de la pipeline...")
    
    # Demander confirmation
    print("\nğŸ“‹ Cette pipeline va:")
    print("   1. ğŸ•·ï¸  Scraper toutes les images du site FlashBack FA")
    print("   2. ğŸ¤– Analyser les images avec GPT-4 Vision")
    print("   3. ğŸ“Š Extraire automatiquement tous les tableaux")
    print("   4. ğŸ’¾ GÃ©nÃ©rer les DataFrames dans flashback_dataframes/")
    print()
    
    choice = input("Voulez-vous continuer ? (O/n): ").lower()
    if choice in ['n', 'non', 'no']:
        print("Pipeline annulÃ©e.")
        return
    
    print("\n" + "="*60)
    
    # Ã‰TAPE 1: Scraping
    scraping_success = await run_scraper()
    
    if not scraping_success:
        print("\nâŒ Ã‰chec du scraping. Pipeline interrompue.")
        return
    
    print("\n" + "="*60)
    
    # Ã‰TAPE 2: Extraction IA
    extraction_success = run_ai_extraction()
    
    # RÃ©sumÃ© final
    end_time = time.time()
    duration = end_time - start_time
    
    print("\n" + "="*60)
    print("ğŸ‰ PIPELINE FLASHBACK FA TERMINÃ‰E")
    print("="*60)
    print(f"â±ï¸  DurÃ©e totale: {duration:.2f} secondes")
    
    if scraping_success and extraction_success:
        print("âœ… SuccÃ¨s complet!")
        print("ğŸ“ RÃ©sultats disponibles dans:")
        print("   ğŸ“· flashback_images/ (images scrapÃ©es)")
        print("   ğŸ“Š flashback_dataframes/ (DataFrames gÃ©nÃ©rÃ©s)")
        print()
        print("ğŸ¯ Vous pouvez maintenant utiliser les DataFrames:")
        print("   from flashback_dataframes.flashback_armes_data import armes_df")
    else:
        print("âš ï¸  Pipeline partiellement rÃ©ussie")
        if scraping_success:
            print("âœ… Scraping: OK")
        else:
            print("âŒ Scraping: Ã‰chec")
        if extraction_success:
            print("âœ… Extraction IA: OK")
        else:
            print("âŒ Extraction IA: Ã‰chec")
    
    print("="*60)

if __name__ == "__main__":
    asyncio.run(main()) 