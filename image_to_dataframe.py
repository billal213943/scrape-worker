#!/usr/bin/env python3
"""
Script d'extraction de tableaux FlashBack FA utilisant OpenAI GPT-4 Vision
Analyse directement toutes les images de tableaux et retourne des DataFrames structur√©s
"""

import pandas as pd
import openai
from openai import OpenAI
import base64
import json
import os
import sys
from pathlib import Path
import logging
from typing import List, Dict, Optional, Tuple
import re
from PIL import Image
import io
import shutil

def load_env_file():
    """Charge le fichier .env s'il existe"""
    env_file = Path('.env')
    if env_file.exists():
        try:
            with open(env_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#') and '=' in line:
                        key, value = line.split('=', 1)
                        os.environ[key] = value
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur lors du chargement du fichier .env: {e}")

# Charger les variables d'environnement depuis .env
load_env_file()

# Configuration du logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class UniversalTableExtractorAI:
    def __init__(self, images_dir: str = "flashback_images", api_key: Optional[str] = None):
        """
        Extracteur universel de tableaux FlashBack FA utilisant GPT-4 Vision
        
        Args:
            images_dir: R√©pertoire contenant les images √† analyser
            api_key: Cl√© API OpenAI (optionnel, peut √™tre d√©finie via variable d'environnement)
        """
        self.images_dir = Path(images_dir)
        
        # Configuration OpenAI
        self.api_key = api_key or os.getenv('OPENAI_API_KEY')
        if not self.api_key:
            logger.error("‚ùå Cl√© API OpenAI non trouv√©e!")
            logger.info("üí° D√©finissez votre cl√© API avec: export OPENAI_API_KEY=your_api_key")
            logger.info("üí° Ou passez-la en param√®tre: UniversalTableExtractorAI(api_key='your_key')")
            sys.exit(1)
        
        self.client = OpenAI(api_key=self.api_key)
        
        # Stockage des DataFrames par type
        self.dataframes = {}

    def encode_image_to_base64(self, image_path: Path) -> str:
        """Encode une image en base64 pour l'API OpenAI"""
        try:
            # Ouvrir et redimensionner l'image si n√©cessaire
            with Image.open(image_path) as img:
                # Convertir en RGB si n√©cessaire
                if img.mode != 'RGB':
                    img = img.convert('RGB')
                
                # Redimensionner si trop grande (limite OpenAI: 20MB, recommand√©: 2048x2048)
                max_size = 2048
                if max(img.width, img.height) > max_size:
                    ratio = max_size / max(img.width, img.height)
                    new_width = int(img.width * ratio)
                    new_height = int(img.height * ratio)
                    img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
                
                # Encoder en base64
                buffer = io.BytesIO()
                img.save(buffer, format='JPEG', quality=85)
                buffer.seek(0)
                return base64.b64encode(buffer.read()).decode('utf-8')
                
        except Exception as e:
            logger.error(f"Erreur lors de l'encodage de {image_path}: {e}")
            return None

    def analyze_all_tables_with_vision(self, image_path: Path) -> Tuple[str, List[Dict]]:
        """Analyse tous les tableaux dans une image avec GPT-4 Vision"""
        try:
            logger.info(f"ü§ñ Analyse IA compl√®te de {image_path.name}")
            
            # Encoder l'image
            base64_image = self.encode_image_to_base64(image_path)
            if not base64_image:
                return None, []
            
            # Prompt universel pour d√©tecter tous les types de tableaux
            system_prompt = """Tu es un expert en analyse de tableaux pour le serveur de jeu FlashBack FA.

            Ton r√¥le est d'identifier et extraire TOUS les tableaux visibles dans l'image, quel que soit leur type (armes, v√©hicules, objets, immobilier, emplois, etc.).

            INSTRUCTIONS:
            1. Examine TOUTE l'image pour d√©tecter tous les tableaux de donn√©es
            2. Pour chaque tableau trouv√©, d√©termine son TYPE (ex: "armes", "v√©hicules", "objets", "immobilier", "emplois")  
            3. Extrait TOUTES les donn√©es de chaque tableau
            4. Conserve la structure et les colonnes exactes de chaque tableau
            5. Les symboles ‚úì/‚úó ou coches/croix = "autoriser"/"interdit"
            6. Retourne un JSON avec la structure suivante:

            {
              "table_type": "nom_du_type_de_tableau",
              "data": [
                {
                  "colonne1": "valeur1",
                  "colonne2": "valeur2",
                  ...
                }
              ]
            }

            Si plusieurs tableaux sont d√©tect√©s, retourne une liste de ces objets.
            Si aucun tableau d√©tect√©, retourne une liste vide []."""
            
            user_prompt = """Analyse cette image FlashBack FA et extrait TOUS les tableaux visibles.

            Pour chaque tableau trouv√©:
            1. Identifie son type (armes, v√©hicules, objets, etc.)
            2. Extrait toutes les donn√©es ligne par ligne
            3. Conserve tous les noms de colonnes exactement comme dans l'image
            4. Convertis les symboles ‚úì/‚úó en "autoriser"/"interdit"

            Retourne UNIQUEMENT un JSON valide avec cette structure:
            [
              {
                "table_type": "type_du_tableau",
                "data": [
                  {"colonne1": "valeur1", "colonne2": "valeur2", ...}
                ]
              }
            ]

            N'ajoute AUCUN texte avant ou apr√®s le JSON."""
            
            # Appel √† l'API OpenAI GPT-4 Vision
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "system",
                        "content": system_prompt
                    },
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": user_prompt
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{base64_image}",
                                    "detail": "high"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=4000,
                temperature=0.1
            )
            
            # Extraire la r√©ponse
            content = response.choices[0].message.content.strip()
            logger.info(f"ü§ñ R√©ponse IA brute: {content[:200]}...")
            
            # Parser le JSON
            try:
                tables = json.loads(content)
                if isinstance(tables, list):
                    logger.info(f"‚úÖ {len(tables)} tableaux d√©tect√©s par l'IA dans {image_path.name}")
                    return None, tables # Return None for table_type as it's not directly used here
                else:
                    logger.warning(f"‚ö†Ô∏è R√©ponse IA non valide pour {image_path.name}: pas une liste")
                    return None, []
                    
            except json.JSONDecodeError as e:
                logger.error(f"‚ùå Erreur JSON pour {image_path.name}: {e}")
                logger.error(f"Contenu re√ßu: {content}")
                
                # Tentative de nettoyage du JSON
                cleaned_content = self.clean_json_response(content)
                if cleaned_content:
                    try:
                        tables = json.loads(cleaned_content)
                        if isinstance(tables, list):
                            logger.info(f"‚úÖ JSON nettoy√©: {len(tables)} tableaux d√©tect√©s")
                            return None, tables
                    except:
                        pass
                
                return None, []
                
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'analyse IA de {image_path}: {e}")
            return None, []

    def clean_json_response(self, content: str) -> Optional[str]:
        """Nettoie la r√©ponse IA pour extraire le JSON valide"""
        try:
            # Chercher le JSON entre crochets (liste)
            json_match = re.search(r'\[.*\]', content, re.DOTALL)
            if json_match:
                return json_match.group(0)
            
            # Chercher le JSON entre accolades (objet unique)
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                return f"[{json_match.group(0)}]"
            
            return None
            
        except Exception as e:
            logger.error(f"Erreur lors du nettoyage JSON: {e}")
            return None

    def normalize_table_data(self, table_data: List[Dict], table_type: str) -> List[Dict]:
        """Normalise les donn√©es d'un tableau selon son type"""
        normalized_data = []
        
        for row in table_data:
            normalized_row = {}
            
            # Normaliser chaque champ
            for key, value in row.items():
                # Nettoyer la cl√©
                clean_key = str(key).strip()
                clean_value = str(value).strip()
                
                # Normaliser les autorisations
                if any(auth_word in clean_key.lower() for auth_word in ['ind√©pendant', 'pf offi', 'gang', 'orga', 'autorisation']):
                    if any(symbol in clean_value.lower() for symbol in ['‚úì', 'oui', 'yes', 'autoris', 'allow', 'permit']):
                        clean_value = 'autoriser'
                    elif any(symbol in clean_value.lower() for symbol in ['‚úó', '‚ùå', 'non', 'no', 'interdit', 'forbid', 'deny']):
                        clean_value = 'interdit'
                
                # Normaliser les prix
                if any(price_word in clean_key.lower() for price_word in ['prix', 'price', 'co√ªt', 'cost', 'revente']):
                    if 'interdit' in clean_value.lower():
                        clean_value = 'INTERDIT'
                    else:
                        price_match = re.search(r'(\d+)', clean_value.replace(' ', '').replace("'", ''))
                        if price_match:
                            price_num = price_match.group(1)
                            if len(price_num) <= 3:
                                clean_value = f"{price_num} 000$"
                            else:
                                clean_value = f"{price_num}$"
                
                # Normaliser les quantit√©s/munitions
                if any(qty_word in clean_key.lower() for qty_word in ['munitions', 'quantit√©', 'max', 'stock']):
                    qty_match = re.search(r'(\d+)', clean_value)
                    if qty_match:
                        clean_value = qty_match.group(1)
                
                normalized_row[clean_key] = clean_value
            
            if normalized_row:  # Ajouter seulement si on a des donn√©es
                normalized_data.append(normalized_row)
        
        return normalized_data

    def process_all_images(self) -> Dict[str, pd.DataFrame]:
        """Traite toutes les images et retourne des DataFrames propres par type de tableau"""
        logger.info(f"ü§ñ Analyse IA - Datasets propres par type de tableau dans {self.images_dir}")
        
        dataframes_by_type = {}
        processed_count = 0
        
        # Traiter chaque image
        image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.gif', '*.bmp', '*.webp']
        for ext in image_extensions:
            for image_path in self.images_dir.glob(ext):
                logger.info(f"üì∑ Analyse IA de {image_path.name}")
                
                # Analyser avec GPT-4 Vision
                table_type, tables = self.analyze_all_tables_with_vision(image_path)
                
                if tables:
                    for table_index, table in enumerate(tables):
                        if isinstance(table, dict):
                            table_data = table.get('data', [])
                            detected_type = table.get('table_type', table_type).lower()
                        else:
                            # Si c'est directement une liste
                            table_data = table if isinstance(table, list) else []
                            detected_type = table_type.lower()
                        
                        if table_data:
                            # Normaliser les donn√©es de ce tableau
                            normalized_data = self.normalize_table_data(table_data, detected_type)
                            
                            if normalized_data:
                                # Cr√©er un nom de dataset propre par type de tableau
                                clean_type_name = re.sub(r'[^a-zA-Z0-9_]', '_', detected_type)
                                clean_type_name = re.sub(r'_+', '_', clean_type_name)
                                clean_type_name = clean_type_name.strip('_')
                                
                                # Si ce type n'existe pas encore, le cr√©er
                                if clean_type_name not in dataframes_by_type:
                                    dataframes_by_type[clean_type_name] = []
                                
                                # Ajouter chaque √©l√©ment avec m√©tadonn√©es
                                for item in normalized_data:
                                    # Nettoyer l'item - garder seulement les colonnes utiles
                                    clean_item = {}
                                    
                                    # Garder seulement les colonnes qui ont des valeurs
                                    for key, value in item.items():
                                        if value and str(value).strip():
                                            clean_item[key] = str(value).strip()
                                    
                                    # Ajouter les m√©tadonn√©es si l'item a du contenu
                                    if clean_item:
                                        clean_item['Source_Image'] = image_path.name
                                        clean_item['Table_Type'] = detected_type.capitalize()
                                        dataframes_by_type[clean_type_name].append(clean_item)
                                
                                logger.info(f"  ‚úÖ Tableau '{detected_type}': {len(normalized_data)} √©l√©ments ajout√©s")
                
                processed_count += 1
        
        # Convertir les listes en DataFrames et supprimer les doublons
        final_dataframes = {}
        
        for table_type, items_list in dataframes_by_type.items():
            if items_list:
                # Supprimer les doublons par nom d'arme/objet
                unique_items = []
                seen_items = set()
                
                for item in items_list:
                    # Utiliser le nom ou les premi√®res valeurs comme cl√© unique
                    name_columns = ['Nom', 'ARMES DE POINGS', 'FUSIL A POMPE', 'ARMES AUTOMATIQUE', 'ARMES LOURDES']
                    item_key = None
                    
                    for col in name_columns:
                        if col in item and item[col] and str(item[col]).strip():
                            item_key = str(item[col]).lower().strip()
                            break
                    
                    # Si pas de nom trouv√©, utiliser les 2 premi√®res valeurs
                    if not item_key:
                        first_values = [v for v in list(item.values())[:2] if v and str(v).strip()]
                        item_key = '|'.join(str(v).lower().strip() for v in first_values)
                    
                    if item_key and item_key not in seen_items and len(item_key) > 2:
                        unique_items.append(item)
                        seen_items.add(item_key)
                
                if unique_items:
                    df = pd.DataFrame(unique_items)
                    final_dataframes[table_type] = df
                    logger.info(f"üéØ Dataset cr√©√© '{table_type}': {len(df)} √©l√©ments uniques")
        
        if not final_dataframes:
            logger.warning("‚ùå Aucun dataset cr√©√© - aucun tableau d√©tect√©")
        else:
            logger.info(f"üéâ {len(final_dataframes)} datasets cr√©√©s par type de tableau:")
            for name, df in final_dataframes.items():
                logger.info(f"   üìä {name}: {len(df)} √©l√©ments")
        
        return final_dataframes

    def export_all_dataframes(self, dataframes: Dict[str, pd.DataFrame]):
        """Exporte tous les DataFrames en code Python uniquement dans un dossier s√©par√©"""
        try:
            # Cr√©er le dossier de sortie
            output_dir = Path("flashback_dataframes")
            output_dir.mkdir(exist_ok=True)
            
            timestamp = pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")
            
            for table_type, df in dataframes.items():
                if not df.empty:
                    # Nettoyer le nom pour les fichiers et variables (remplacer espaces par underscores)
                    clean_table_name = re.sub(r'[^a-zA-Z0-9_]', '_', table_type.lower())
                    clean_table_name = re.sub(r'_+', '_', clean_table_name)  # √âviter les underscores multiples
                    clean_table_name = clean_table_name.strip('_')  # Enlever les underscores en d√©but/fin
                    
                    # Export Python code uniquement dans le dossier s√©par√©
                    py_file = output_dir / f"flashback_{clean_table_name}_data.py"
                    with open(py_file, 'w', encoding='utf-8') as f:
                        f.write("import pandas as pd\n\n")
                        f.write(f"# Donn√©es {table_type} extraites par IA GPT-4 Vision depuis les images FlashBack FA\n")
                        f.write(f"# D√âTECTION AUTOMATIQUE PAR INTELLIGENCE ARTIFICIELLE\n")
                        f.write(f"# Timestamp: {timestamp}\n\n")
                        
                        # Variables avec noms propres (pas d'espaces)
                        var_name = f"{clean_table_name}_data"
                        df_name = f"{clean_table_name}_df"
                        
                        f.write(f"{var_name} = {df_name} = pd.DataFrame([\n")
                        
                        for _, row in df.iterrows():
                            f.write("    {")
                            items = []
                            for col in df.columns:
                                value = row[col] if pd.notna(row[col]) else ""
                                # √âchapper les guillemets dans les valeurs
                                escaped_value = str(value).replace('"', '\\"')
                                items.append(f'"{col}": "{escaped_value}"')
                            f.write(", ".join(items))
                            f.write("},\n")
                        
                        f.write("])\n\n")
                        
                        # Ajouter un commentaire d'utilisation
                        f.write(f"# Utilisation:\n")
                        f.write(f"# from flashback_dataframes.flashback_{clean_table_name}_data import {var_name}, {df_name}\n")
                        f.write(f"# print({df_name}.head())\n")
                        f.write(f"# print(f'{{len({df_name})}} √©l√©ments dans ce dataset')\n")
                    
                    logger.info(f"‚úÖ '{table_type}' export√© vers {py_file}")
                    logger.info(f"   üìù Variables: {var_name}, {df_name}")
            
            logger.info(f"üìÅ Tous les DataFrames export√©s dans le dossier: {output_dir.absolute()}")
            
        except Exception as e:
            logger.error(f"Erreur lors de l'export: {e}")

def clean_output_directory(output_dir: str = "flashback_dataframes"):
    """Nettoie compl√®tement le dossier de sortie avant la nouvelle extraction"""
    output_path = Path(output_dir)
    
    if output_path.exists():
        try:
            # Supprimer tout le dossier et son contenu
            shutil.rmtree(output_path)
            print(f"üóëÔ∏è Dossier {output_dir}/ vid√© (anciens datasets supprim√©s)")
        except Exception as e:
            print(f"‚ö†Ô∏è Impossible de vider {output_dir}/: {e}")
    
    # Recr√©er le dossier vide
    try:
        output_path.mkdir(exist_ok=True)
        print(f"üìÅ Dossier {output_dir}/ recr√©√© (pr√™t pour nouveaux datasets)")
    except Exception as e:
        print(f"‚ùå Impossible de cr√©er {output_dir}/: {e}")

def main():
    """Fonction principale"""
    print("üéÆ FLASHBACK FA - EXTRACTEUR IA UNIVERSEL")
    print("ü§ñ ANALYSE PAR INTELLIGENCE ARTIFICIELLE GPT-4 VISION")
    print("üìä EXTRACTION DE TOUS LES TABLEAUX (armes, v√©hicules, objets, etc.)")
    print("=" * 70)
    
    # Nettoyer le dossier de sortie avant de commencer
    clean_output_directory()
    
    # V√©rifier la cl√© API
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        print("‚ùå Cl√© API OpenAI non trouv√©e!")
        print()
        print("üîß Solutions:")
        print("   1. D√©finir la variable d'environnement: export OPENAI_API_KEY=your_api_key")
        print("   2. Ou cr√©er un fichier .env avec: OPENAI_API_KEY=your_api_key")
        print()
        print("üí° Obtenez votre cl√© API sur: https://platform.openai.com/api-keys")
        return
    
    print(f"‚úÖ Cl√© API OpenAI configur√©e (***{api_key[-6:]})")
    
    # Cr√©er l'extracteur IA
    ai_extractor = UniversalTableExtractorAI("flashback_images")
    
    # V√©rifier le dossier d'images
    if not ai_extractor.images_dir.exists():
        print(f"‚ùå Dossier {ai_extractor.images_dir} non trouv√©!")
        print("   Lancez d'abord le scraper pour t√©l√©charger les images.")
        return
    
    # Compter les images
    image_count = sum(1 for ext in ['*.jpg', '*.jpeg', '*.png', '*.gif', '*.bmp', '*.webp'] 
                     for _ in ai_extractor.images_dir.glob(ext))
    
    if image_count == 0:
        print(f"‚ùå Aucune image trouv√©e dans {ai_extractor.images_dir}")
        return
    
    print(f"üì∑ {image_count} images trouv√©es pour analyse IA")
    
    # Traiter les images avec l'IA
    print("\nü§ñ Analyse par intelligence artificielle...")
    print("üîç GPT-4 Vision va analyser chaque image et extraire TOUS les tableaux")
    print("üìä D√©tection automatique: armes, v√©hicules, objets, immobilier, emplois, etc.")
    dataframes_by_type = ai_extractor.process_all_images()
    
    if dataframes_by_type:
        total_elements = sum(len(df) for df in dataframes_by_type.values())
        print(f"\nüìä {total_elements} √©l√©ments d√©tect√©s par l'IA dans {len(dataframes_by_type)} types de tableaux!")
        
        print("\nüî§ Aper√ßu des donn√©es extraites par IA:")
        for name, df in dataframes_by_type.items():
            print(f"\n--- {name} ({len(df)} √©l√©ments) ---")
            print(df.head(3))  # Afficher 3 premi√®res lignes
        
        # Exporter au format demand√©
        ai_extractor.export_all_dataframes(dataframes_by_type)
        print("\n‚úÖ Donn√©es IA export√©es vers le dossier flashback_dataframes/")
        
        # Statistiques d√©taill√©es
        print(f"\nüìà Statistiques compl√®tes:")
        for name, df in dataframes_by_type.items():
            print(f"   üìã {name}: {len(df)} √©l√©ments")
            # Afficher les colonnes principales
            main_columns = [col for col in df.columns if not col.startswith('Source_') and col != 'Table_Type']
            print(f"      Colonnes: {', '.join(main_columns[:5])}" + ("..." if len(main_columns) > 5 else ""))
        
        print(f"\nüéØ TOTAL: {total_elements} √©l√©ments extraits automatiquement par l'IA!")
        print("üéÆ Chaque type d'arme/objet dans son dataset s√©par√© (plus propre!)")
        
    else:
        print("‚ùå Aucun tableau d√©tect√© par l'IA.")
        print("   V√©rifiez que les images contiennent des tableaux de donn√©es lisibles.")
        print("   L'IA recherche: armes, v√©hicules, objets, immobilier, emplois, etc.")

if __name__ == "__main__":
    main() 